#------------------------------------------------------------------------------------------------------------------
# WORKLOAD GENERATOR CONFIG FILE
# This is a configuration file for a simple SWF-based and AleaNG-compatible workload generator
# It will create correct: 
#  1) job file (in extended SWF format, see SWF description: https://www.cs.huji.ac.il/labs/parallel/workload/swf.html) 
#  2) machine file (describe clusters)
#  3) queue file (describe queues and their limits and priorities)
#  4) group file (describe user-groups and their limits)
#  5) user file (describe users, their groups, their relative shares and limits)
#------------------------------------------------------------------------------------------------------------------

# DATA_SET name (output workload name)
workload_filename=Example6.swf

# DATA_SET directory (output directory name)
workload_dir=generated_workloads

# NUMBER of ACTIVE DAYS: how many days the users submit their jobs
days=365

# SYSTEM LOAD: target system load, e.g., 0.8 means that the generator will create workload that occupies ~80% of all CPU resources (ideally packed)
# useful to influence the "backlog" of waiting jobs (1.5 -> huge, 0.99 -> large, 0.6 -> small)
system_load=0.85

# Number of random unique workloads that will be created using this setup
workload_instances=1

# URGENT JOBS: how many jobs (in %) will belong to urgent QoS (urgent QoS jobs have higher priority). 
load_percentage_urgent=5


# USERS (comma separated list): two classes are supported (urgent and normal)
# format: user_name <TAB> shares(int) <TAB> CPU_limit_quota(int)
# keywords for job size: [tiny, large, small] - used by generator to identify job size   
# keywords for user priority (QoS) group: [urgent, normal] - used by generator to identify job class 
user_names_urgent=urgent_large_user \t 2 \t 500,urgent_tiny_user \t 2 \t 500
user_names_normal=normal_large_user \t 1 \t 400,normal_small_user \t 1 \t 400

# GROUPS (comma separated list): two groups are supported in this generator (priority and normal). Priority (urgent) group must come first (need to have id==0)
# format: group_name <TAB> shares(int) <TAB> CPU_limit_quota(int)
group_names=priority_group \t 2 \t 500,normal_group \t 1 \t 400

# QUEUES (comma separated list): specification of queues, their limits and queue priorities (used to determine which queue to traverse first, second, etc.)
# Priority (urgent) queue must come first (need to have id==0)
# format: queue_name <TAB> CPU_limit_quota(int) <TAB> priority(int)
queue_names=priority_queue \t 500 \t 50,default_queue \t 400 \t 20

# CLUSTERS (comma separated list): specification of the clusters. Cluster "property" String can be used to steer jobs to suitable clusters.  
# format: cluster_name <TAB> #of nodes(int) <TAB> CPUs per node(int) <TAB> processing_speed(int) <TAB> RAM(GB)(int) <TAB> property (String) <TAB> #of GPUs(int)
machine_names = cl_dedicated \t 4 \t 4 \t 1 \t 256 \t dedicated \t 4,cl_normal_1 \t 6 \t 64 \t 1 \t 256 \t normal \t 8
# the total number of CPUs in the system
total_cpus = 400

# FULL NODE JOBS [true/false] - decides whether jobs allocate whole nodes or not (false => space-sharing can appear as multiple jobs may run on the same node)
allocate_whole_nodes = false

# NUMBER of NODES to be ALLOCATED by one JOB
number_of_nodes_for_job = 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 4

# BATCH SIZE: how many jobs are submitted within one batch (batch = jobs submitted at once at a given time by a given user). 
# User-to-batch size matching is done using the keywords [tiny, large, small] in user names. 
# The smaller the jobs is (small, tiny) the higher the number of jobs.
batch_size_large=2
batch_size_small=4
batch_size_tiny=16

# JOB CPU requirements (comma separated list): actual values are chosen randomly from these lists of eligible CPU requirements 
# User-to-job size matching is done using the keywords [tiny, large, small] in user names. 
# (tiny, small => used for tiny, small users; large => used for large users)
tiny_job_sizes = 1, 2
small_job_sizes = 4, 8, 12
large_job_sizes = 16, 24, 32, 40

# JOB WALLTIME (comma separated list): eligible walltime limits (actual job runtimes are randomly generated to be smaller)
job_runtime_limit = 600, 900, 1200, 1800, 2700, 3600, 7200

# INTER BATCH IDLE TIME (comma separated list): how many seconds pass between two different batches
# different eligible interarrival times are used for urgent and normal jobs, respectively
# A proper Inter batch idle period matching is done using the keywords [tiny, large, small] in user names. 
# interarrival times are prolonged (more spread out) when desired system load is lower: (inter_batch_idle_period * (1.0 / system_load))
inter_batch_idle_period_urgent = 1800, 3600, 5400, 7200
inter_batch_idle_period_normal = 300, 600, 900, 1200, 1500, 1800, 2100, 2400, 2700, 3600

